{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lunch Time Python\n",
    "\n",
    "## Lunch 4: pytest\n",
    "\n",
    "<img style=\"width: 400px; float: left;\" src=\"https://docs.pytest.org/en/7.0.x/_static/pytest_logo_curves.svg\">\n",
    "\n",
    "[pytest](https://docs.pytest.org/) is a widely used Python test framework, which makes it easy to write small and readable tests, and also offers more advanced features such as fixtures and mocks. There is also a large ecosystem of plugins providing additional functionality.\n",
    "\n",
    "*Press `Spacebar` to go to the next slide (or `?` to see all navigation shortcuts)*\n",
    "\n",
    "[Lunch Time Python](https://ssciwr.github.io/lunch-time-python/), [Scientific Software Center](https://ssc.iwr.uni-heidelberg.de), [Heidelberg University](https://www.uni-heidelberg.de/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why write tests?\n",
    "\n",
    "- ensure correctness\n",
    "- maintain correctness\n",
    "- find bugs earlier and more easily\n",
    "- allow refactoring without fear\n",
    "- allow others to contribute without unknowingly breaking stuff\n",
    "- can complement documentation as examples of use\n",
    "- give others confidence in your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# pytest installation\n",
    "\n",
    "- Conda: `conda install pytest`\n",
    "- Pip: `python -m pip install pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# First steps\n",
    "\n",
    "## Create a test\n",
    "\n",
    "1. create a file that starts with `test_`, e.g. `test_math.py`\n",
    "2. add a function to it that starts with `test_` and asserts things, e.g.\n",
    "```python\n",
    "# in file: test_math.py\n",
    "def test_add():\n",
    "        assert 1 + 1 == 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Run the tests\n",
    "\n",
    "3. run `pytest -v` or `python -m pytest -v`\n",
    "\n",
    "```bash\n",
    "================ test session starts =======================\n",
    "platform linux -- Python 3.10.2, pytest-7.0.0, pluggy-1.0.0\n",
    "rootdir: /home/liam/test\n",
    "plugins: anyio-3.5.0\n",
    "collected 1 item                                                                                                                                                                                  \n",
    "\n",
    "test_math.py::test_add PASSED  \n",
    "                                                       [100%]\n",
    "\n",
    "====================== 1 passed in 0.00s ====================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What just happened?\n",
    "\n",
    "- pytest looks for all files that start with `test_`\n",
    "- it collects all functions in these files that start with `test_`\n",
    "- it runs them all, and reports PASS/FAIL for each assertion in each function\n",
    "\n",
    "## Some things we didn't do\n",
    "\n",
    "- import a test library\n",
    "- inherit from some base test class\n",
    "- use some special `assertEqual` function\n",
    "- register our test file or test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Simple pytest test strategy\n",
    "\n",
    "- for each file `abc.py`, add a `test_abc.py`\n",
    "- for each function `foo()` in `abc.py`, add a `test_foo()` to `test_abc.py`\n",
    "- inside `test_foo()` assert things involving `foo()` that should be true \n",
    "- that's it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ipytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## disclaimer\n",
    "\n",
    "- For demonstration purposes, these tests will be written inside this jupyter notebook\n",
    "- We'll use a helper library `ipytest` to call pytest on them from inside the notebook\n",
    "- But generally I would recommend putting functions and tests into files and running pytest directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    !pip install ipytest -qqq\n",
    "import ipytest\n",
    "import pytest\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "\n",
    "def test_math():\n",
    "    assert 1 + 1 == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Failing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -q\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    return 2 * x\n",
    "\n",
    "\n",
    "def g(x):\n",
    "    return f(x) + 3\n",
    "\n",
    "\n",
    "def test_math():\n",
    "    a = 2\n",
    "    b = 3\n",
    "    assert f(a) * g(b) == 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -q\n",
    "\n",
    "\n",
    "def test_list():\n",
    "    a = [1, 2, 5, 8]\n",
    "    b = [1, 2, 5, 8]\n",
    "    assert a == b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -q\n",
    "\n",
    "\n",
    "def test_exception():\n",
    "    my_list = [1, 2, 3]\n",
    "    with pytest.raises(IndexError):\n",
    "        my_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -q\n",
    "\n",
    "\n",
    "def test_exception():\n",
    "    my_list = [1, 2, 3]\n",
    "    with pytest.raises(Exception) as e:\n",
    "        my_list[5]\n",
    "    assert e.type == IndexError\n",
    "    assert \"out of range\" in str(e.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Temporary files\n",
    "\n",
    "- often need to write to a temporary file in a test\n",
    "- simply add `tmp_path` as an argument to your test function\n",
    "- pytest will provide a unique temporary path object for each test\n",
    "- this is an example of a *fixture*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -qs\n",
    "\n",
    "\n",
    "def test_write(tmp_path):\n",
    "    print(tmp_path)\n",
    "    assert str(tmp_path) != \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Monkey-patching\n",
    "\n",
    "- a fixture to temporarily modify an object, dict or environment variable\n",
    "- all modifications are undone after the test is finished\n",
    "- add `monkeypatch` as an argument to your test function\n",
    "- provides various methods, e.g.\n",
    "  - `monkeypatch.setattr(obj, name, value)`\n",
    "  - `monkeypatch.setenv(name, value)`\n",
    "  - `monkeypatch.syspath_prepend(path)`\n",
    "  - `monkeypatch.chdir(path)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -qs\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def test_env(monkeypatch):\n",
    "    assert os.getenv(\"TEST_API_KEY\") == None\n",
    "    monkeypatch.setenv(\"TEST_API_KEY\", \"abc123\")\n",
    "    assert os.getenv(\"TEST_API_KEY\") == \"abc123\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fixtures\n",
    "\n",
    "- a way to provide context (e.g. data or environment) to a test\n",
    "- test \"requests\" a fixture by declaring it as an argument\n",
    "- various built-in fixtures (`tmp_path`, `monkeypatch`, ...)\n",
    "- you can create your own with the `@pytest.fixture` decorator\n",
    "- for each test function argument, pytest looks for a fixture with the same name\n",
    "- fixtures can themselves request other fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "# a fixture to provide some data to a test\n",
    "@pytest.fixture\n",
    "def colours():\n",
    "    return [\"red\", \"green\", \"blue\"]\n",
    "\n",
    "\n",
    "def test_colours(colours):\n",
    "    assert colours[0] == \"red\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def colours():\n",
    "    return [\"red\", \"green\", \"blue\"]\n",
    "\n",
    "\n",
    "# a fixture that itself requests another fixture\n",
    "@pytest.fixture\n",
    "def sorted_colours(colours):\n",
    "    return sorted(colours)\n",
    "\n",
    "\n",
    "def test_colours(sorted_colours):\n",
    "    assert sorted_colours[0] == \"blue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "# a fixture that uses monkeypatch to set an environment variable\n",
    "@pytest.fixture\n",
    "def api_key(monkeypatch):\n",
    "    monkeypatch.setenv(\"TEST_API_KEY\", \"abc123\")\n",
    "\n",
    "\n",
    "def test_missing_api_key():\n",
    "    assert os.getenv(\"TEST_API_KEY\") == None\n",
    "\n",
    "\n",
    "def test_api_key(api_key):\n",
    "    assert os.getenv(\"TEST_API_KEY\") == \"abc123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "# a parameterized fixture: test will be repeated for each parameter\n",
    "@pytest.fixture(params=[\"red\", \"green\", \"blue\", \"yellow\"])\n",
    "def colour(request):\n",
    "    return request.param\n",
    "\n",
    "\n",
    "def test_colour(colour):\n",
    "    assert len(colour) >= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test grouping\n",
    "\n",
    "- put functions into a class whose name begins with `Test`\n",
    "- a class can request a fixture, all member functions then have this fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "\n",
    "class TestMath:\n",
    "    def test_add(self):\n",
    "        assert 1 + 1 == 2\n",
    "\n",
    "    def test_mul(self):\n",
    "        assert 2 * 2 == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Marking tests\n",
    "\n",
    "- mark tests with attributes using `@pytest.mark` decorator\n",
    "- common use cases\n",
    "  - `skipif` to conditionally skip a test\n",
    "    - e.g. depending on python version or platform\n",
    "  - `xfail` to mark a test that is expected to fail\n",
    "    - e.g. a test that documents a known bug that is not yet fixed\n",
    "- can also mark a test class to mark all tests within that class\n",
    "- can also create your own custom markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "@pytest.mark.xfail(reason=\"bug from issue #123\")\n",
    "def test_add():\n",
    "    assert 1 + 1 == 3\n",
    "\n",
    "\n",
    "@pytest.mark.skipif(not sys.platform.startswith(\"win\"), reason=\"windows only test\")\n",
    "def test_mul():\n",
    "    assert 2 * 2 == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parameterizing tests\n",
    "\n",
    "- can parameterize tests using the `@pytest.mark.parameterize` decorator\n",
    "- takes comma-delimeted list of arguments as a string\n",
    "- followed by a list of tuples of argument values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"n\", [1, 2, 3])\n",
    "def test_n(n):\n",
    "    assert n > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%ipytest -vv\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"n,n_squared\", [(1, 1), (2, 4), (3, 9)])\n",
    "def test_n(n, n_squared):\n",
    "    assert n * n == n_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "- pytest is very easy to get started with and use\n",
    "- just writing test functions with assertions already provides a lot of value\n",
    "- fixtures allow you to provide context to your test functions\n",
    "- parameterizing fixtures and/or tests can turn a single test into many test cases\n",
    "- (many) more features at [docs.pytest.org](https://docs.pytest.org/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
